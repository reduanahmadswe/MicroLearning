# üéôÔ∏è AI Voice Tutor API Documentation

## Overview
AI Voice Tutor ‡¶π‡¶≤‡ßã ‡¶è‡¶ï‡¶ü‡¶ø ‡¶∞‡¶ø‡¶Ø‡¶º‡ßá‡¶≤-‡¶ü‡¶æ‡¶á‡¶Æ ‡¶≠‡¶Ø‡¶º‡ßá‡¶∏-‡¶¨‡ßá‡¶∏‡¶° ‡¶ü‡¶ø‡¶â‡¶ü‡¶∞‡¶ø‡¶Ç ‡¶∏‡¶ø‡¶∏‡ßç‡¶ü‡ßá‡¶Æ ‡¶Ø‡ßá‡¶ñ‡¶æ‡¶®‡ßá ‡¶∏‡ßç‡¶ü‡ßÅ‡¶°‡ßá‡¶®‡ßç‡¶ü‡¶∞‡¶æ ‡¶è‡¶Ü‡¶á ‡¶è‡¶∞ ‡¶∏‡¶æ‡¶•‡ßá ‡¶ï‡¶•‡¶æ ‡¶¨‡¶≤‡ßá ‡¶∂‡¶ø‡¶ñ‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡¶¨‡ßá‡•§ ‡¶è‡¶ü‡¶ø OpenAI Whisper (Speech-to-Text) ‡¶è‡¶¨‡¶Ç TTS (Text-to-Speech) ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßá‡•§

## Features
- ‚úÖ ‡¶∞‡¶ø‡¶Ø‡¶º‡ßá‡¶≤-‡¶ü‡¶æ‡¶á‡¶Æ ‡¶≠‡¶Ø‡¶º‡ßá‡¶∏ ‡¶ï‡¶®‡¶≠‡¶æ‡¶∞‡ßç‡¶∏‡ßá‡¶∂‡¶®
- ‚úÖ ‡¶Æ‡¶æ‡¶≤‡ßç‡¶ü‡¶ø-‡¶≤‡ßç‡¶Ø‡¶æ‡¶ô‡ßç‡¶ó‡ßÅ‡¶Ø‡¶º‡ßá‡¶ú ‡¶∏‡¶æ‡¶™‡ßã‡¶∞‡ßç‡¶ü (‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ, ‡¶á‡¶Ç‡¶∞‡ßá‡¶ú‡¶ø, ‡¶π‡¶ø‡¶®‡ßç‡¶¶‡¶ø)
- ‚úÖ ‡¶ï‡¶æ‡¶∏‡ßç‡¶ü‡¶Æ ‡¶≠‡¶Ø‡¶º‡ßá‡¶∏ ‡¶∏‡¶ø‡¶≤‡ßá‡¶ï‡¶∂‡¶® (‡¶™‡ßÅ‡¶∞‡ßÅ‡¶∑/‡¶Æ‡¶π‡¶ø‡¶≤‡¶æ/‡¶∂‡¶ø‡¶∂‡ßÅ)
- ‚úÖ ‡¶ï‡¶®‡¶≠‡¶æ‡¶∞‡ßç‡¶∏‡ßá‡¶∂‡¶® ‡¶π‡¶ø‡¶∏‡ßç‡¶ü‡ßã‡¶∞‡¶ø ‡¶ü‡ßç‡¶∞‡ßç‡¶Ø‡¶æ‡¶ï‡¶ø‡¶Ç
- ‚úÖ ‡¶ü‡¶™‡¶ø‡¶ï-‡¶¨‡ßá‡¶∏‡¶° ‡¶≤‡¶æ‡¶∞‡ßç‡¶®‡¶ø‡¶Ç ‡¶∏‡ßá‡¶∂‡¶®
- ‚úÖ ‡¶á‡¶Æ‡ßã‡¶∂‡¶®‡¶æ‡¶≤ ‡¶∏‡ßç‡¶ü‡ßá‡¶ü ‡¶ü‡ßç‡¶∞‡ßç‡¶Ø‡¶æ‡¶ï‡¶ø‡¶Ç
- ‚úÖ XP ‡¶∞‡¶ø‡¶ì‡¶Ø‡¶º‡¶æ‡¶∞‡ßç‡¶° ‡¶∏‡¶ø‡¶∏‡ßç‡¶ü‡ßá‡¶Æ

---

## API Endpoints

### 1. Create Voice Session
‡¶®‡¶§‡ßÅ‡¶® ‡¶≠‡¶Ø‡¶º‡ßá‡¶∏ ‡¶ü‡¶ø‡¶â‡¶ü‡¶∞‡¶ø‡¶Ç ‡¶∏‡ßá‡¶∂‡¶® ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡ßÅ‡¶®‡•§

**Endpoint:** `POST /api/voice-tutor/sessions`

**Headers:**
```json
{
  "Authorization": "Bearer <access_token>"
}
```

**Request Body:**
```json
{
  "topic": "JavaScript Arrays",
  "language": "en",
  "voiceType": "female"
}
```

**Response:** `201 Created`
```json
{
  "success": true,
  "message": "Voice session created successfully",
  "data": {
    "_id": "674b2c1a3f8e4d2b5c6a7e89",
    "user": "674a1b2c3d4e5f6a7b8c9d0e",
    "sessionId": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
    "startTime": "2025-11-30T10:00:00.000Z",
    "topic": "JavaScript Arrays",
    "language": "en",
    "voiceType": "female",
    "conversationHistory": [],
    "emotionalState": "neutral",
    "status": "active",
    "createdAt": "2025-11-30T10:00:00.000Z",
    "updatedAt": "2025-11-30T10:00:00.000Z"
  }
}
```

**Field Descriptions:**
- `topic` (optional): ‡¶≤‡¶æ‡¶∞‡ßç‡¶®‡¶ø‡¶Ç ‡¶ü‡¶™‡¶ø‡¶ï
- `language` (optional): `bn` | `en` | `hi` (default: `en`)
- `voiceType` (optional): `male` | `female` | `child` (default: `female`)

---

### 2. Send Voice Message
‡¶≠‡¶Ø‡¶º‡ßá‡¶∏ ‡¶Æ‡ßá‡¶∏‡ßá‡¶ú ‡¶™‡¶æ‡¶†‡¶æ‡¶® ‡¶è‡¶¨‡¶Ç ‡¶è‡¶Ü‡¶á ‡¶∞‡ßá‡¶∏‡¶™‡¶®‡ßç‡¶∏ ‡¶™‡¶æ‡¶®‡•§

**Endpoint:** `POST /api/voice-tutor/message`

**Headers:**
```json
{
  "Authorization": "Bearer <access_token>"
}
```

**Request Body (Audio):**
```json
{
  "sessionId": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
  "audioData": "base64_encoded_audio_data"
}
```

**Request Body (Text):**
```json
{
  "sessionId": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
  "text": "What is array map function?"
}
```

**Response:** `200 OK`
```json
{
  "success": true,
  "message": "Voice message processed successfully",
  "data": {
    "sessionId": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
    "text": "The map() function creates a new array by calling a function on every element in the original array. For example, if you have [1, 2, 3] and you map each number to double itself, you get [2, 4, 6].",
    "audioUrl": "data:audio/mpeg;base64,//uQx...",
    "suggestions": [
      "Can you explain that in simpler terms?",
      "Can you give me an example?",
      "What should I learn next?"
    ]
  }
}
```

**Field Descriptions:**
- `sessionId` (required): ‡¶∏‡ßá‡¶∂‡¶® ‡¶Ü‡¶á‡¶°‡¶ø
- `audioData` (optional): Base64 ‡¶è‡¶®‡¶ï‡ßã‡¶°‡ßá‡¶° ‡¶Ö‡¶°‡¶ø‡¶ì ‡¶°‡¶æ‡¶ü‡¶æ
- `text` (optional): ‡¶ü‡ßá‡¶ï‡ßç‡¶∏‡¶ü ‡¶Æ‡ßá‡¶∏‡ßá‡¶ú (audioData ‡¶Ö‡¶•‡¶¨‡¶æ text ‡¶Ø‡ßá‡¶ï‡ßã‡¶®‡ßã ‡¶è‡¶ï‡¶ü‡¶ø ‡¶•‡¶æ‡¶ï‡¶§‡ßá ‡¶π‡¶¨‡ßá)

---

### 3. End Voice Session
‡¶≠‡¶Ø‡¶º‡ßá‡¶∏ ‡¶∏‡ßá‡¶∂‡¶® ‡¶∂‡ßá‡¶∑ ‡¶ï‡¶∞‡ßÅ‡¶® ‡¶è‡¶¨‡¶Ç XP ‡¶™‡¶æ‡¶®‡•§

**Endpoint:** `PATCH /api/voice-tutor/sessions/:sessionId/end`

**Headers:**
```json
{
  "Authorization": "Bearer <access_token>"
}
```

**Response:** `200 OK`
```json
{
  "success": true,
  "message": "Voice session ended successfully",
  "data": {
    "_id": "674b2c1a3f8e4d2b5c6a7e89",
    "user": "674a1b2c3d4e5f6a7b8c9d0e",
    "sessionId": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
    "startTime": "2025-11-30T10:00:00.000Z",
    "endTime": "2025-11-30T10:15:30.000Z",
    "duration": 930,
    "topic": "JavaScript Arrays",
    "conversationHistory": [...],
    "status": "completed",
    "createdAt": "2025-11-30T10:00:00.000Z",
    "updatedAt": "2025-11-30T10:15:30.000Z"
  }
}
```

**XP Calculation:**
- ‡¶™‡ßç‡¶∞‡¶§‡¶ø ‡¶∏‡ßá‡¶ï‡ßá‡¶®‡ßç‡¶° = 1 XP
- ‡¶Æ‡ßç‡¶Ø‡¶æ‡¶ï‡ßç‡¶∏‡¶ø‡¶Æ‡¶æ‡¶Æ = 50 XP ‡¶™‡ßç‡¶∞‡¶§‡¶ø ‡¶∏‡ßá‡¶∂‡¶®

---

### 4. Get Session History
‡¶®‡¶ø‡¶∞‡ßç‡¶¶‡¶ø‡¶∑‡ßç‡¶ü ‡¶∏‡ßá‡¶∂‡¶®‡ßá‡¶∞ ‡¶ï‡¶®‡¶≠‡¶æ‡¶∞‡ßç‡¶∏‡ßá‡¶∂‡¶® ‡¶π‡¶ø‡¶∏‡ßç‡¶ü‡ßã‡¶∞‡¶ø ‡¶¶‡ßá‡¶ñ‡ßÅ‡¶®‡•§

**Endpoint:** `GET /api/voice-tutor/sessions/:sessionId`

**Headers:**
```json
{
  "Authorization": "Bearer <access_token>"
}
```

**Response:** `200 OK`
```json
{
  "success": true,
  "message": "Session history retrieved successfully",
  "data": {
    "_id": "674b2c1a3f8e4d2b5c6a7e89",
    "sessionId": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
    "topic": "JavaScript Arrays",
    "conversationHistory": [
      {
        "role": "user",
        "content": "What is array map function?",
        "timestamp": "2025-11-30T10:01:00.000Z",
        "transcript": "What is array map function?"
      },
      {
        "role": "assistant",
        "content": "The map() function creates a new array...",
        "timestamp": "2025-11-30T10:01:05.000Z",
        "audioUrl": "data:audio/mpeg;base64,..."
      }
    ],
    "status": "active"
  }
}
```

---

### 5. Get User Sessions
‡¶á‡¶â‡¶ú‡¶æ‡¶∞‡ßá‡¶∞ ‡¶∏‡¶¨ ‡¶≠‡¶Ø‡¶º‡ßá‡¶∏ ‡¶∏‡ßá‡¶∂‡¶® ‡¶≤‡¶ø‡¶∏‡ßç‡¶ü ‡¶¶‡ßá‡¶ñ‡ßÅ‡¶®‡•§

**Endpoint:** `GET /api/voice-tutor/sessions?page=1&limit=10`

**Headers:**
```json
{
  "Authorization": "Bearer <access_token>"
}
```

**Query Parameters:**
- `page` (optional): ‡¶™‡ßá‡¶ú ‡¶®‡¶Æ‡ßç‡¶¨‡¶∞ (default: 1)
- `limit` (optional): ‡¶™‡ßç‡¶∞‡¶§‡¶ø ‡¶™‡ßá‡¶ú‡ßá ‡¶∞‡ßá‡¶ú‡¶æ‡¶≤‡ßç‡¶ü (default: 10)

**Response:** `200 OK`
```json
{
  "success": true,
  "message": "User sessions retrieved successfully",
  "data": [
    {
      "_id": "674b2c1a3f8e4d2b5c6a7e89",
      "sessionId": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
      "topic": "JavaScript Arrays",
      "duration": 930,
      "status": "completed",
      "createdAt": "2025-11-30T10:00:00.000Z"
    }
  ],
  "meta": {
    "page": 1,
    "limit": 10,
    "total": 25,
    "totalPages": 3
  }
}
```

---

## Error Responses

### 404 Not Found
```json
{
  "success": false,
  "message": "Voice session not found",
  "errorMessages": [
    {
      "path": "",
      "message": "Voice session not found"
    }
  ]
}
```

### 400 Bad Request
```json
{
  "success": false,
  "message": "No message content provided",
  "errorMessages": [
    {
      "path": "",
      "message": "No message content provided"
    }
  ]
}
```

### 401 Unauthorized
```json
{
  "success": false,
  "message": "Unauthorized access",
  "errorMessages": [
    {
      "path": "",
      "message": "You are not authorized"
    }
  ]
}
```

---

## Usage Flow

### Step 1: Create Session
```javascript
const response = await fetch('/api/voice-tutor/sessions', {
  method: 'POST',
  headers: {
    'Authorization': 'Bearer <token>',
    'Content-Type': 'application/json'
  },
  body: JSON.stringify({
    topic: 'Python Functions',
    language: 'en',
    voiceType: 'female'
  })
});

const { data } = await response.json();
const sessionId = data.sessionId;
```

### Step 2: Record Audio (Frontend)
```javascript
// Web Audio API
const mediaRecorder = new MediaRecorder(stream);
let audioChunks = [];

mediaRecorder.ondataavailable = (event) => {
  audioChunks.push(event.data);
};

mediaRecorder.onstop = async () => {
  const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
  const reader = new FileReader();
  
  reader.onloadend = async () => {
    const base64Audio = reader.result.split(',')[1];
    
    // Send to API
    await sendVoiceMessage(sessionId, base64Audio);
  };
  
  reader.readAsDataURL(audioBlob);
};
```

### Step 3: Send Voice Message
```javascript
const response = await fetch('/api/voice-tutor/message', {
  method: 'POST',
  headers: {
    'Authorization': 'Bearer <token>',
    'Content-Type': 'application/json'
  },
  body: JSON.stringify({
    sessionId,
    audioData: base64Audio
  })
});

const { data } = await response.json();

// Play AI response
const audio = new Audio(data.audioUrl);
audio.play();

// Display text
console.log(data.text);
```

### Step 4: End Session
```javascript
await fetch(`/api/voice-tutor/sessions/${sessionId}/end`, {
  method: 'PATCH',
  headers: {
    'Authorization': 'Bearer <token>'
  }
});
```

---

## Technical Details

### Audio Format Support
- **Input**: WebM, MP3, WAV, OGG
- **Output**: MP3 (Base64 encoded)
- **Max Size**: 25MB

### Voice Options
| Voice Type | OpenAI Voice | Description |
|-----------|-------------|-------------|
| `male` | onyx | ‡¶ó‡¶≠‡ßÄ‡¶∞ ‡¶™‡ßÅ‡¶∞‡ßÅ‡¶∑ ‡¶ï‡¶£‡ßç‡¶† |
| `female` | nova | ‡¶∏‡ßç‡¶™‡¶∑‡ßç‡¶ü ‡¶Æ‡¶π‡¶ø‡¶≤‡¶æ ‡¶ï‡¶£‡ßç‡¶† |
| `child` | shimmer | ‡¶®‡¶∞‡¶Æ ‡¶∂‡¶ø‡¶∂‡ßÅ ‡¶ï‡¶£‡ßç‡¶† |

### Language Support
- `bn`: ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ (Bangla)
- `en`: English
- `hi`: ‡§π‡§ø‡§®‡•ç‡§¶‡•Ä (Hindi)

### Rate Limits
- **Max 50 messages** per session
- **Max 30 minutes** per session
- **Max 10 active sessions** per user

---

## Integration Example (React)

```typescript
import { useState, useRef } from 'react';

function VoiceTutor() {
  const [sessionId, setSessionId] = useState<string | null>(null);
  const [isRecording, setIsRecording] = useState(false);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  
  const startSession = async () => {
    const res = await fetch('/api/voice-tutor/sessions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${token}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        topic: 'JavaScript',
        language: 'en',
        voiceType: 'female'
      })
    });
    
    const { data } = await res.json();
    setSessionId(data.sessionId);
  };
  
  const startRecording = async () => {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    const mediaRecorder = new MediaRecorder(stream);
    mediaRecorderRef.current = mediaRecorder;
    
    const audioChunks: Blob[] = [];
    
    mediaRecorder.ondataavailable = (e) => {
      audioChunks.push(e.data);
    };
    
    mediaRecorder.onstop = async () => {
      const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
      const reader = new FileReader();
      
      reader.onloadend = async () => {
        const base64 = (reader.result as string).split(',')[1];
        await sendMessage(base64);
      };
      
      reader.readAsDataURL(audioBlob);
    };
    
    mediaRecorder.start();
    setIsRecording(true);
  };
  
  const stopRecording = () => {
    mediaRecorderRef.current?.stop();
    setIsRecording(false);
  };
  
  const sendMessage = async (audioData: string) => {
    const res = await fetch('/api/voice-tutor/message', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${token}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        sessionId,
        audioData
      })
    });
    
    const { data } = await res.json();
    
    // Play response
    const audio = new Audio(data.audioUrl);
    audio.play();
  };
  
  return (
    <div>
      {!sessionId ? (
        <button onClick={startSession}>Start Voice Session</button>
      ) : (
        <button 
          onClick={isRecording ? stopRecording : startRecording}
        >
          {isRecording ? 'Stop Recording' : 'Start Recording'}
        </button>
      )}
    </div>
  );
}
```

---

## Best Practices

1. **Session Management**
   - ‡¶∏‡ßá‡¶∂‡¶® ‡¶∂‡ßá‡¶∑‡ßá ‡¶Ö‡¶¨‡¶∂‡ßç‡¶Ø‡¶á `end` API ‡¶ï‡¶≤ ‡¶ï‡¶∞‡ßÅ‡¶®
   - Inactive ‡¶∏‡ßá‡¶∂‡¶® ‡¶Ö‡¶ü‡ßã-‡¶ü‡¶æ‡¶á‡¶Æ‡¶Ü‡¶â‡¶ü: 30 ‡¶Æ‡¶ø‡¶®‡¶ø‡¶ü

2. **Audio Quality**
   - ‡¶≠‡¶æ‡¶≤‡ßã ‡¶Æ‡¶æ‡¶á‡¶ï‡ßç‡¶∞‡ßã‡¶´‡ßã‡¶® ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßÅ‡¶®
   - Background noise ‡¶ï‡¶Æ ‡¶∞‡¶æ‡¶ñ‡ßÅ‡¶®
   - Sample rate: 16kHz+

3. **Error Handling**
   - Network error ‡¶π‡¶≤‡ßá retry ‡¶ï‡¶∞‡ßÅ‡¶®
   - Audio transcription fail ‡¶π‡¶≤‡ßá text fallback ‡¶¶‡¶ø‡¶®

4. **Performance**
   - Audio chunks 5-10 ‡¶∏‡ßá‡¶ï‡ßá‡¶®‡ßç‡¶°‡ßá‡¶∞ ‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá ‡¶∞‡¶æ‡¶ñ‡ßÅ‡¶®
   - Base64 encoding ‡¶∏‡¶æ‡¶á‡¶ú ‡¶¨‡¶°‡¶º ‡¶π‡¶≤‡ßá compression ‡¶ï‡¶∞‡ßÅ‡¶®

---

## Future Enhancements
- üîú Emotion detection from voice
- üîú Real-time streaming (WebSocket)
- üîú Video call with AI avatar
- üîú Multi-participant sessions
- üîú Voice accent customization
